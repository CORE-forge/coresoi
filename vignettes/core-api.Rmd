---
title: "Performing a request to CORE API via R"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{core-api}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, eval=FALSE}
library(coresoi)
```


## What's an api
A good data science endeavor is powered by interesting data sets. While services such as Kaggle provide free data sets to eager data scientists, APIs are another popular method for accessing and acquiring interesting data.

Instead of downloading a dataset, APIs allow programmers to request data directly from specific websites via an Application Programming Interface (thus, "API"). Many prominent websites, such as Reddit, Twitter, and Facebook, provide APIs via which data analysts and data scientists may gain access to fascinating data. This is also true when you might want to serve your R function to non-R users. In interdisciplinary departments such as DS people need to show results to colleagues without having them to run code on their machine, it can be models or plots. The barres which may prevent this might be team's non-techical expertise, absence of reproducible envs or just people (like many DEs) using Python ðŸ‘Ž.
APIs in this sense make you able to abtractize the business logic to code.



## What's an api in R

The word "API" refers to the location where one computer program interacts with another or with itself. We'll be dealing with online APIs in this lesson, where two separate computers â€” a client and a server â€” will connect with each other to request and deliver data, respectively.

APIs provide data scientists with a sophisticated method of requesting clean and vetted data from a website. When a website, such as Facebook, creates an API, they are effectively creating a computer that will wait for data requests.

What makes this valuable? Contrast the API method with traditional web scraping. When a programmer scrapes a web page, the data is sent in the form of a jumbled piece of HTML. While there are packages that make parsing HTML text simple, these are all cleaning procedures that must be completed before we can even get our hands on the data we need!


## perform core-api request in 
Since CORE API under hood uses this package we might be interested to see how it behaves when it is called via R.
To work with APIs in R, we need to bring in some libraries. These libraries take all of the complexities of an API request and wrap them up in functions that we can use in single lines of code. The R library that weâ€™ll be using are `httr2`.

```{r insalling, eval=F}
library(httr2)
core_api_url = ""
req <- request("https://r-project.org")
req
```

After downloading the libraries, weâ€™ll be able to use them in our R scripts or RMarkdown files.

Use `req_perform()` to perform the request, retrieving a response:


```{r reqperform, eval = FALSE}
resp <- req_perform(req)
resp
```

