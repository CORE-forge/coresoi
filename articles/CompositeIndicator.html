<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="coresoi">
<title>Composite Indicator (CI) • coresoi</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><link href="../deps/Dosis-0.4.6/font.css" rel="stylesheet">
<link href="../deps/JetBrains_Mono-0.4.6/font.css" rel="stylesheet">
<link href="../deps/Lora-0.4.6/font.css" rel="stylesheet">
<!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Composite Indicator (CI)">
<meta property="og:description" content="coresoi">
<meta property="og:image" content="https://core-forge.github.io/coresoi/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><script async defer src="https://hypothes.is/embed.js"></script>
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">coresoi</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.2.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/coresoi.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/summary.html">summary</a>
    <a class="dropdown-item" href="../articles/ChoiceOfElementaryIndicators.html">Choice of elementary indicators</a>
    <a class="dropdown-item" href="../articles/DataSelectionArchitecture.html">Data selection and architecture</a>
    <a class="dropdown-item" href="../articles/CompositeIndicator.html">Composite Indicator (CI)</a>
    <a class="dropdown-item" href="../articles/tryCoresoiWithYourData.html">Try `coresoi` with you own data</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/CORE-forge/coresoi/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Composite Indicator (CI)</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/CORE-forge/coresoi/blob/HEAD/vignettes/articles/CompositeIndicator.Rmd" class="external-link"><code>vignettes/articles/CompositeIndicator.Rmd</code></a></small>
      <div class="d-none name"><code>CompositeIndicator.Rmd</code></div>
    </div>

    
    
<div class="section level3">
<h3 id="normalisation-methods">
<strong>Normalisation methods</strong><a class="anchor" aria-label="anchor" href="#normalisation-methods"></a>
</h3>
<p>Normalisation is required in order to make the indicators comparable
when they have different measurement units or when they have a
particularly skew distribution. In addition, according to the
aggregation method used, it is also required when indicators have
different polarity. With this regard, it is common to normalise
indicators that are negatively correlated with the latent phenomenon to
be measured (negative ‘polarity’) so that they become positively
correlated with the latent phenomenon (positive ‘polarity’). In this
way, larger values of the normalised indicator result in larger values
of the CI. There are various normalisation methods, such as ranking,
standardisation (or z-scores), re-scaling (or min-max transformation),
indexing (index number transformation or ‘distance’ to a reference), and
categorisation. A complete review and a thorough discussion of possible
normalisation methods is provided in OECD (2008) and in Otoiu et
al. (2021) . Here we will provide only the two that are relevant to our
application, as many red flags are binary. Let be the q-th simple
indicator, for q = 1, …, Q, of the c-th unit, for c = 1, …, C; Q is the
overall number of simple indicators and C is the overall number of
units.</p>
<ul>
<li>Standardisation (z-scores): For each indicator, the difference
between the original values and the mean over the units is divided by
the standard deviation. In this way, indicators have a common scale with
mean 0 and standard deviation 1. If an indicator has negative polarity,
standardized values can be multiplied by -1.</li>
</ul>
<p><span class="math display">\[
\begin{equation} I_{qc} = \frac{x_{qc}-\mu_q(x_{qc})}{\sigma_q(x_{qc})}
\end{equation}
\]</span></p>
<ul>
<li>Rescaling (Min-Max transformation). The difference between the
original values and the minimum is divided by the range of an indicator.
Transformed indicators have a common scale ranging between 0 and 1.
Therefore, this transformation should be applied only to non-binary red
flags. If an indicator has negative polarity, the complement of rescaled
values with respect to 1 can be calculated.</li>
</ul>
<p><span class="math display">\[
\begin{equation} I_{qc} = \frac{x_{qc} - min_c(x_{qc})}{max_c(x_{qc})-
min_c(x_{qc})} \end{equation}
\]</span></p>
<p>Standardisation and rescaling are both applicable to indicators with
positive, negative and zero values, and they are both sensitive to
outliers. Standardisation provides indicators with equal variances, it
is not very suitable for bounded indicators and it produces negative
values, while rescaling provides indicators with equal range, it is not
very suitable for unbounded indicators.</p>
</div>
<div class="section level3">
<h3 id="weighting-and-aggregation-schemes">
<strong>Weighting and aggregation schemes</strong><a class="anchor" aria-label="anchor" href="#weighting-and-aggregation-schemes"></a>
</h3>
<p>In order to obtain a single CI from a set of individual indicators,
two other important choices are at stake: the weighting system and the
aggregation scheme. The former implies the scale of importance of each
individual indicator, while the latter identifies the technique
(compensatory, partially compensatory or non-compensatory) for
summarising the individual indicator values into a single number.
Weights should reflect the relative importance of the individual
indicators and heavily influence the outcomes of the CI. The most widely
used techniques for weighting individual indicators are the following
(Otoiu et al. 2021): a) no weighting, that implies that equal weights
are applied to all individual indicators; b) subjective or expert
weighting, where group of specialists define weights for each indicator;
and c) objective or ‘data-driven’ weighting, as when the coefficients of
the first factor of Principal Component Analysis are used as weights
(this is the set of weights that explains the largest variation in the
original indicators). The choice of the weighting system is usually by
far the most influential among the others on the final CI value and
related rankings <span class="citation">(Gnaldi and Ranalli
2015a)</span>. The choice of the aggregation scheme, on the other hand,
heavily depends on the degree of compensability or substitutability of
the individual indicators. A compensatory approach involves the use of
linear functions, such as a linear combination of the normalised
individual indicators, whereas a partially compensatory or
non-compensatory approach requires the use of non-linear functions, such
as with a multiplicative approach. In the first case, the CI for unit c
can be obtained as follows,</p>
<p><span class="math display">\[
\begin{equation} C_I = \sum_{q=1}^{Q} w_q I_{qc} \end{equation}
\]</span></p>
<p>where <span class="math inline">\(0 \leq w_q \leq 1\)</span> is the
weight given to indicator <span class="math inline">\(q\)</span>, and it
is such that <span class="math inline">\(\begin{equation} C_I =
\sum_{q=1}^{Q} w_q = 1 \end{equation}\)</span>. When using a geometric
aggregation rule,</p>
<p><span class="math display">\[
\begin{equation} C_{I_c}=\prod_{q=1}^{Q} I_{q_c}^{w_q} \end{equation}
\]</span></p>
<p>partial compensability is allowed. This choice is advisable in our
case, if, on a conservative perspective, even a small achievement in any
of the red flags is crucial for the overall risk of corruption. The
additive and the multiplicative aggregation functions can be seen as
special cases of a generalised mean or power mean of order r, where for
the arithmetic mean and for the geometric mean. Alternative aggregation
methods are, among others, the Wroclaw Taxonomic Method, the Mean-Min
Function, and the Mazziotta-Pareto Index (for details see Otoiu et al.,
2021).</p>
</div>
<div class="section level3">
<h3 id="multivariate-analysis-for-the-study-of-the-data-structure">
<strong>Multivariate analysis for the study of the data
structure</strong><a class="anchor" aria-label="anchor" href="#multivariate-analysis-for-the-study-of-the-data-structure"></a>
</h3>
<p>It is broadly known that corruption and corruption risk is a complex
and latent phenomenon and the red flag indicators, obtained in a
particular context, consist in the observable manifestation of it. When
building a CI of corruption risk, the set of available red flags is
transformed in a unique measure of the phenomenon they contribute to
measure. In doing this, however, the phenomenon is considered as if it
were unidimensional, as it is assumed that each single red flag is
expression of the same unique underlying construct (corruption). On the
other hand, it might be reasonable to suppose the existence of several
dimensions or groups of red flag indicators, which measure, from
different perspectives, several aspects of the same (multidimensional)
phenomenon.<br>
For this reason, a dimensionality assessment is crucial in the process
of construction of every CI, with the aim of discovering whether the
phenomenon at issue could be considered unidimensional or
multidimensional. To this end, multivariate statistical techniques are
available for acknowledging the multidimensionality of a latent
phenomenon, especially in choosing number and composition (in terms of
observable indicators) of the sub-dimensions to be accounted for. In
this regard, these methods can have confirmatory or exploratory nature.
The former type requires an a priori specification of the dimensionality
structure – i.e., which dimensions characterise the phenomenon and which
indicators contribute to measure each one – and allows us to assess the
goodness of fit of this solution to the data at hand. However, it is
difficult to have prior information on its dimensionality structure and,
consequently, it is not trivial to specify it in practice. Conversely,
the latter kind of methods do not assume any particular dimensionality
structure and perform an exploratory analysis of all the possible
dimensionality solutions, proposing those that better fit to the data at
hand. The selection of the final solution can be carried out by means of
objective (statistical) and/or subjective criteria. As mentioned above,
this dimensionality evaluation is a fundamental step when building a CI.
It helps to consider the suitability of the data at issue for
representing the latent phenomenon under study and will contribute to
understand the implications of other methodological choices (e.g.,
related to weighting, aggregation, etc.) during the entire process of
composite indicator construction. In fact, individual indicators are
often chosen arbitrarily, paying little attention to the relationship
among them and leading to the “indicator rich but information poor”
environment, that is, composites that do not contribute to add
knowledge, but conversely are overwhelmed, confused and misleading
(OECD, 2008).</p>
<div class="section level4">
<h4 id="principal-component-analysis">
<em>Principal Component Analysis</em><a class="anchor" aria-label="anchor" href="#principal-component-analysis"></a>
</h4>
<p>Principal Component Analysis i.e. PCA <span class="citation">(Abdi
and Williams 2010)</span> is one of the most widely known method of
multivariate statistical analysis. Given a set of Q variables (or
indicators), x1, …, xQ, the purpose is to find few linear combinations
of them (i.e, the principal components, PC) in order to explain their
variance as much as possible. In fact, even if we have Q variables, most
of their variability may be accounted for by only a small number of
them, say R. The idea behind this approach is that the single principal
component is measuring a different dimension of the data and should
include those indicators that mostly contribute to this measurement,
hence those with a high degree of correlation among them.<br>
The principal components, denoted by Pr, are therefore estimated by
combining (linearly) the observed Q variables so that they are
uncorrelated each other. Theoretically, given Q variables, it is
possible to find as many principal components, that is,</p>
<p><span class="math display">\[
\begin{equation} P_1=\alpha_{Q1}x_1+\alpha_{Q2}x_2+...+\alpha_{QQ}x_Q
\end{equation}
\]</span></p>
<p>where <span class="math inline">\(\alpha_{rq}\)</span> are weights
(also called component of factor loadings) related to variable <span class="math inline">\(x_q\)</span> and component <span class="math inline">\(P_r\)</span>, <span class="math inline">\(r,q =
1,…,Q\)</span>, such that the principal components are uncorrelated and
contribute to explain a decreasing share of the overall variability of
<span class="math inline">\(x\)</span>, that is, the first <span class="math inline">\(PC (r = 1)\)</span> accounts for the maximum
possible proportion of variance in the observed variables, the second
<span class="math inline">\(PC (r = 2)\)</span> accounts for the maximum
of the remaining variance, and so on. The objective is therefore to
select the first <span class="math inline">\(R &lt;&lt; Q\)</span>
principal components in order to explain a high amount of variance of
the observed data. Principal components are extracted by computing the
eigenvalues of the <span class="math inline">\(Q x Q\)</span> covariance
matrix computed on the observed variables. The <em>eigenvalues</em>
correspond to the variances of the principal components and in theory
<span class="math inline">\(Q\)</span> eigenvalues can be computed (as
many as the variables), but some of them can be negligible. Moreover,
the sum of the eigenvalues is equal to the sum of the variances of the
indicators, then the ratio between each eigenvalue and their sum is the
proportion of variance that each one contributes to explain.
Consequently, in order to select the number of components to retain
(i.e., R), an analysis of the eigenvalue decomposition of the covariance
matrix is needed. In practice, it is common to consider a predefined
share of total variance explained (e.g., 70% or 80%), then R will be
equal to the number of eigenvalues that contribute to explain this part
of variance. However, two or three PCs are often selected in order to
have a graphical representation of the resulting solution.</p>
</div>
<div class="section level4">
<h4 id="factor-analysis">
<em>factor analysis</em><a class="anchor" aria-label="anchor" href="#factor-analysis"></a>
</h4>
<p>Like PCA, Factor Analysis (FA; McDonald, 2014) aims at finding a
reduced number of unobserved variables (i.e., the latent factors) from
an observed pool of <span class="math inline">\(Q\)</span> indicators,
say <span class="math inline">\(x1, …, xQ\)</span>, in order to
underline the relationships among them. Differently from PCA, FA is
based on a statistical model, through which the data variance can be
decomposed into two parts, that explained by the factors and that still
unexplained. Hence, given a set of Q variables (indicators) and R
factors, FA considers the following model:</p>
<p><span class="math display">\[
\begin{equation}
x_1=\gamma_{Q1}F_1+\gamma_{Q2}F_2+...+\gamma_{QR}F_R+\epsilon_q
\end{equation}
\]</span></p>
<p>where <span class="math inline">\(\gamma_{qr}\)</span> represents the
factor loading of indicator q on factor r, Fr is a common factor, with r
= 1,…,R, and <span class="math inline">\(\epsilon_q\)</span> is a unique
factor, with <span class="math inline">\(q = 1,…,Q\)</span>, and
corresponds to the error term in the regression model, with zero mean,
independent and identically distributed with respect to each variable.
Factor loadings summarise the relationships between indicator and factor
and can be seen as standardised regression coefficients, ranging between
<strong>-1</strong> and <strong>1</strong>. Several approaches are
available for extracting the factors, such as PCA, maximum likelihood,
centroid method, principal axis method, etc. However, the crucial issue
is how many factors retain and different methods are proposed in this
regard, most of them based on the eigenvalue decomposition of the
covariance matrix among the indicators. The Kaiser criterion suggests
dropping all factors with eigenvalues below 1 as it is supposed that
their contribution to the variance explained is negligible. Moreover,
like for PCA, one can decide to set a predetermined and desired share of
explained variance (e.g., 80%) and retain a number of factors that
allows for this. Alternatively, another proposal is to inspect the scree
plot, that is, a plot of the successive eigenvalues and look when it
drops sharply and becomes flat, also known as elbow method <span class="citation">(Syakur et al. 2018)</span>. Other proposals to select
the number of factors are, for example, the Joliffe criterion or the
parallel analysis, but it is important to remark that, despite a
solution is the optimal one according to, say, objective criteria, it
could lead to results of difficult interpretability and comprehension.
For this reason, together to indices closely related to
statistical/objective criteria, a degree of subjectivity should be
adopted. Once the number of factors is selected, a good practice is to
perform a rotation of the factor loadings for reasons of
interpretability of the resulting solution. It would be ideal that a
simple solution was reached, that is, a clear pattern of loadings where
each indicator has only one high value on one factor, and near-zero
values on the others, so that each indicator could be associated with
one and only one factor. Several rotation methods exist and can be
divided into two groups, those based on orthogonality (uncorrelation)
among factors (such as varimax, quartimax and equimax), and those
relaxing the orthogonality constraint, the so-called oblique rotation
methods (such as oblimin and promax).</p>
</div>
<div class="section level4">
<h4 id="item-response-theory">
<em>item response theory</em><a class="anchor" aria-label="anchor" href="#item-response-theory"></a>
</h4>
<p>Item Response Theory (IRT) models (see <span class="citation">Bartolucci, Dardanoni, and Peracchi (2015)</span> for
an outline) can be considered as one the most well-known latent variable
models. They work with categorical indicators and are based on latent
variables, also called latent traits, which represent the latent
phenomenon under study (i.e., corruption risk in our case). IRT models
allow us to mathematically specify the probability of observing a value
in the indicator as monotonic non-decreasing function of indicator
characteristics (difficulty, discrimination, etc.) and latent trait
level, namely the Item Characteristic Curve (ICC). The most famous IRT
model is the Rasch model (Rasch, 1961), especially used in the
educational field, where the indicators at issue (e.g., items of an
assessment test) are dichotomous (1 = correct, 0 = wrong response). The
Rasch model has the following <strong>ICC</strong>:</p>
<p><span class="math display">\[
\begin{equation} P\left(x_{cq}=1\mid
\theta_c\right)=\frac{\exp\left(\theta_c -\beta_q
\right)}{1+\exp\left(\theta_c-\beta_q\right)} \end{equation}
\]</span></p>
<p>where <span class="math inline">\(x_{}cq\)</span> denotes the
indicator <span class="math inline">\(q\)</span> of unit <span class="math inline">\(\theta_c\)</span>, is the latent trait level of
unit c and <span class="math inline">\(\beta_q\)</span> is the
difficulty parameter of item <span class="math inline">\(q\)</span>,
<span class="math inline">\(c = 1,…,C\)</span> and <span class="math inline">\(q = 1,…,Q\)</span>. The latter parameter defines
the location of the ICC over the latent trait space and can be
interpreted as the latent trait level needed to have with 50% of
probability. The Rasch model is also known as 1PL (one-parameter
logistic) model, as it considers <span class="math inline">\(i\)</span>.
the logistic function for defining the probability defined on the
left-hand side and ii. only one parameter on the right-hand side. In
fact, it assumes that each item (indicator) has the same discrimination
power, that is, the capacity of that item to differentiate between units
with different latent trait levels. If we relax this constraint, we have
the 2PL (two-parameter logistic) model (Birnbaum, 1968):</p>
<p><span class="math display">\[
\begin{equation} P\left(x_{cq}=1\mid
\theta_c\right)=\frac{\exp\left[\gamma_q\left(\theta_c
-\beta_q\right)\right]}{1+\exp\left[\gamma_q\left(\theta_c-\beta_q\right)\right]}
\end{equation}
\]</span></p>
<p>where <span class="math inline">\(\gamma_q\)</span> is the
discriminating parameters, which defines the slope of the ICC. Other IRT
models can be specified according to the type of indicators (dichotomous
or polytomous), the number of parameters used for defining the ICC (one,
two, three, etc.), the distribution of the latent variable (discrete or
continuous), and the link function (i.e., the function that connects the
parameters – right hand side of the above equations – with the
conditional probability of observing a value in the indicator – left
hand side). IRT models were initially defined for modelling
unidimensional phenomena, represented by a univariate random (and
latent) variable, namely . However, multidimensional IRT models are
proposed (Reckase, 2009), where the latent variable is multivariate,
hence a random vector, in which each component represents a dimension of
the phenomenon at issue. Like for PCA or FA, confirmatory or exploratory
approaches are available also in the IRT framework.</p>
</div>
<div class="section level4">
<h4 id="structural-equation-modelling">
<em>Structural Equation Modelling</em><a class="anchor" aria-label="anchor" href="#structural-equation-modelling"></a>
</h4>
<p>Structural Equation Modelling i.e. SEM (<span class="citation">Raykov
and Marcoulides (2000)</span> ; Nachtigall et al., 2003) is a flexible
framework that integrates several techniques of multivariate statistical
analysis. Its main purpose is to estimate the presence and magnitude of
relationships among variables using some key features of path analysis
(Wright, 1934). For example, let us consider three variables, <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>
and <span class="math inline">\(Z\)</span>, whose relationships can be
summarised as reported in Figure 1. We can notice that the effect of X
on Y is two-fold: i. a direct effect between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> (represented by the direct path from
<span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span>), and ii. an indirect effect mediated
through Z (represented by the path from <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span> via <span class="math inline">\(Z\)</span>). Hence, the total effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> is obtained by summing up these two
components and the path analysis techniques are suitable for estimating
direct, indirect, and total effects among variables. Moreover, <span class="math inline">\(SEM\)</span> can deal with latent variables, of
which the observed indicators are overt manifestations. Therefore, two
different stages of modelling approaches are available in <span class="math inline">\(SEM\)</span>: i. that related to the measurement
models (e.g., one for each supposed latent variables), which specify the
relationship between observed variables and the underlying latent one,
and ii. that regarding the connections among latent variables, defined
through the structural models.</p>
<p><img src="assets/05-irt_path_diagram.png"></p>
<p>An example of a rather simple <span class="math inline">\(SEM\)</span> is reported in Figure 2, where we
have 7 indicators <span class="math inline">\((X1,…,X7)\)</span> that
concur to measure three latent variables <span class="math inline">\((Z1, Z2, Z3)\)</span>. In this situation we need
three measurement models for handling the relationships between the
observed indicators and the three latent variables. Moreover, the
structural model specifies that <span class="math inline">\(Z1\)</span>
and <span class="math inline">\(Z3\)</span> have both a direct effect of
<span class="math inline">\(Z2\)</span>, but they also affect each
other.</p>
<p><img src="assets/06-example_SEM.png"></p>
<p>Several logical steps contribute to define an analysis strategy based
on SEM. The first step is the model specification, which specifies the
supposed relationships among the variables (observed and unobserved)
according to the theory or previous knowledge on the phenomenon under
study. Before fitting the model, one has to check about its
identification, in order to avoid that it was under-identified, since in
this case it would be impossible estimate model parameters. This stage
refers to an assessment of the quality/quantity of observed indicators
for representing the latent variables – see <span class="citation">Rigdon (1995)</span>]for more specific details.
Afterwards, the model has to be fitted on the data at hand and evaluated
using quantitative indices about the goodness of fit, such as the Root
Mean Square Error of Approximation, Comparative Fit Index, Bayesian
Information Criterion, Akaike Information Criterion, etc. If necessary,
the model can be modified in order to improve the model fitting, with
contextual repetition of all the above steps.</p>
</div>
<div class="section level4">
<h4 id="sensitivity-analysis">
<em>Sensitivity analysis</em><a class="anchor" aria-label="anchor" href="#sensitivity-analysis"></a>
</h4>
<p>The selection of individual indicators, the choice of the
normalisation method, of the weighting system, and of the aggregation
scheme are all potential sources of uncertainty that affect both the
variance of the CIs and the variability of any ranking based on CIs. In
other words, it is expected that the choice to include a particular
indicator in the CI, or the choice to employ a normalisation scheme
(rather than a different one) can have an impact on the rankings of the
individual units according to the CI. In this context, sensitivity
analysis is considered as an appropriate tool to assess such
uncertainties as it studies how the variation in the output (CI values
and rankings) can be apportioned to different sources of variation in
the assumptions, and how the given CI depends upon the information fed
into it. Sensitivity analysis can help to gauge the robustness of the CI
value. In particular, the CI can be computed using all the possible
combinations of the alternative possible choices. For each unit, the
distribution of all the possible Cis highlights whether that unit is
systematically labeled as corrupt or only under particular
circumstances. <strong>ANOVA</strong> and/or regression analysis can
also be conducted on the outcome of the sensitivity exercise to evaluate
which of the factors involved in the construction of the CI is more
relevant and influential <span class="citation">(Gnaldi and Ranalli
2015b)</span></p>
</div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-abdi2010" class="csl-entry">
Abdi, Hervé, and Lynne J. Williams. 2010. <span>“Principal Component
Analysis.”</span> <em>Wiley Interdisciplinary Reviews: Computational
Statistics</em> 2 (4): 433–59. <a href="https://doi.org/10.1002/wics.101" class="external-link">https://doi.org/10.1002/wics.101</a>.
</div>
<div id="ref-bartolucci2015" class="csl-entry">
Bartolucci, Francesco, Valentino Dardanoni, and Franco Peracchi. 2015.
<span>“Ranking Scientific Journals Via Latent Class Models for
Polytomous Item Response Data.”</span> <em>Journal of the Royal
Statistical Society Series A: Statistics in Society</em> 178 (4):
1025–49. <a href="https://doi.org/10.1111/rssa.12106" class="external-link">https://doi.org/10.1111/rssa.12106</a>.
</div>
<div id="ref-gnaldi2015" class="csl-entry">
Gnaldi, Michela, and M. Giovanna Ranalli. 2015a. <span>“Measuring
University Performance by Means of Composite Indicators: A Robustness
Analysis of the Composite Measure Used for the Benchmark of Italian
Universities.”</span> <em>Social Indicators Research</em> 129 (2):
659–75. <a href="https://doi.org/10.1007/s11205-015-1116-1" class="external-link">https://doi.org/10.1007/s11205-015-1116-1</a>.
</div>
<div id="ref-gnaldi2015a" class="csl-entry">
———. 2015b. <span>“Measuring University Performance by Means of
Composite Indicators: A Robustness Analysis of the Composite Measure
Used for the Benchmark of Italian Universities.”</span> <em>Social
Indicators Research</em> 129 (2): 659–75. <a href="https://doi.org/10.1007/s11205-015-1116-1" class="external-link">https://doi.org/10.1007/s11205-015-1116-1</a>.
</div>
<div id="ref-raykov2000" class="csl-entry">
Raykov, Tenko, and George A. Marcoulides. 2000. <span>“A Method for
Comparing Completely Standardized Solutions in Multiple Groups.”</span>
<em>Structural Equation Modeling: A Multidisciplinary Journal</em> 7
(2): 292–308. <a href="https://doi.org/10.1207/s15328007sem0702_9" class="external-link">https://doi.org/10.1207/s15328007sem0702_9</a>.
</div>
<div id="ref-rigdon1995" class="csl-entry">
Rigdon, Edward E. 1995. <span>“A Necessary and Sufficient Identification
Rule for Structural Models Estimated in Practice.”</span>
<em>Multivariate Behavioral Research</em> 30 (3): 359–83. <a href="https://doi.org/10.1207/s15327906mbr3003_4" class="external-link">https://doi.org/10.1207/s15327906mbr3003_4</a>.
</div>
<div id="ref-syakur2018" class="csl-entry">
Syakur, M A, B K Khotimah, E M S Rochman, and B D Satoto. 2018.
<span>“Integration k-Means Clustering Method and Elbow Method for
Identification of the Best Customer Profile Cluster.”</span> <em>IOP
Conference Series: Materials Science and Engineering</em> 336 (April):
012017. <a href="https://doi.org/10.1088/1757-899x/336/1/012017" class="external-link">https://doi.org/10.1088/1757-899x/336/1/012017</a>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Niccolo Salvini, Simone DelSarto, Michela Gnaldi.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
