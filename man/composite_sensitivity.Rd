% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/composite.R
\name{composite_sensitivity}
\alias{composite_sensitivity}
\title{Perform a complete sensitivity analysis of the composite indicator}
\usage{
composite_sensitivity(indicator_list, cutoff = c(0.9, 0.95, 0.99, 0.995), ...)
}
\arguments{
\item{indicator_list}{list of outputs about each indicator computable for the target unit
(e.g., company or contracting authority), as returned by \code{\link[=ind_all]{ind_all()}}.}

\item{cutoff}{vector of thresholds for normalising the indicators (i.e., for their dichotomisation)}

\item{...}{optional arguments of \code{\link[mirt:mirt]{mirt::mirt()}} function (for getting IRT weights).}
}
\value{
a list with two versions (wide and long) of a dataframe (\code{sens_wide} and \code{sens_long}),
which includes, for each target unit, all the possible values of the composite indicator obtained
by combining methodological choices and indicator removals. See Details.
}
\description{
\code{composite_sensitivity} performs a complete sensitivity analysis of the composite
indicator, by computing it using all the possible combinations of methodological choices --
about \strong{normalisation}, \strong{management of missing values}, \strong{weighting} and \strong{aggregation} -- as well as evaluating
the contribution of each elementary indicator to the final composite, by removing each indicator
at a time from the computation.
\emph{Note: the unique normalisation method considered within the CO.R.E. project is the 'dichotomisation'.}
\emph{Then, the sensitivity is based on the choice of the threshold. See Details.}
}
\details{
This is the main function for carrying out the sensitivity analysis of the composite
indicator. It requires a list of indicator outputs as returned by \code{\link[=ind_all]{ind_all()}}. This list is given to the internal function
\code{\link[=create_indicator_matrix]{create_indicator_matrix()}} for obtaining the data matrix of elementary indicators.

Thereafter, several steps for the sensitivity analysis are performed, as follows.
\enumerate{
\item Elementary indicators are \emph{normalised} through the 'dichotomisation' method, using several
thresholds provided through argument \code{cutoff}.
\item \emph{Missing values} in the elementary indicators (if any) are managed with both the proposed methods,
that is, by replacing missing values with '0' ('not at risk'), or by means of logistic regression
models (see internal function \code{\link[=manage_missing]{manage_missing()}}).
\item Vectors of \emph{weights} are obtained according to all the three proposed ways, that is, equal weights,
expert weights and IRT weights (see \code{\link[=get_weights]{get_weights()}}). The last method can require much time, as it
depends on the data at hand, which are different every time according to step 1 and 2.
\item \emph{Composite indicator computation}. For each target unit, the composite indicator is computed
on the basis of each combination of the above methodological choices (steps 1-3),
hence \eqn{k \times 2 \times 3} combinations, where \eqn{k} is the number of normalisation thresholds
(\code{cutoff}). In addition, the composite indicator is computed by removing each elementary indicator
at a time from the computation. Finally, given \eqn{Q} elementary indicators, the composite indicator is
computed, for each target unit, \eqn{k \times 2 \times 3 \times (Q+1)} times.
}

Results are returned in two dataframes. In the \strong{wide} version (\code{sens_wide}), we have the target unit
in the rows and as many columns as the number of the above combinations, which report
the computed composite. Specifically, the first column is the target unit ID, whereas the subsequent
columns contain the composite computed according to the different combinations (steps 1-4 above).
The names of these columns have the following structure: c\strong{x}.m\strong{y}.w_\strong{abc}.\strong{rrr}, where
\itemize{
\item \strong{x} is the cut-off value for normalising the elementary indicators (e.g., 0.95);
\item \strong{y} is the label for missing management method (0 or 1, see [\code{\link[=manage_missing]{manage_missing()}});
\item \strong{abc} is the weighting scheme ('eq' for equal weights; 'exp' for expert weights;
'irt' for IRT weights);
\item \strong{rrr} is the indication of the removed indicator ('all' means that no indicator is removed).
}

For example, column labelled as \code{c0.95.m0.w_eq.all} contains the composite indicators computed using:
\strong{0.95} as cut-off value for the normalisation; method \emph{'0'} for missing management;
equal weights (\strong{w_eq}); without removal of elementary indicators (\strong{all}).

The function directly returns also the \strong{long} version of the above dataframe (\code{sens_long}), where
the target unit is repeated for each 'sensitivity combination'. Here, the columns refer to the variables
that enter in the sensitivity analysis. In particular, we have:
\itemize{
\item \code{aggregation_name}: target unit ID
\item \code{ci}: value of the composite
\item \code{cutoff}: possible cut-off values for the normalisation
\item \code{miss}: '0' or '1'
\item \code{weights}: 'eq', 'exp' or 'irt'
\item \code{ind_removed}: 'none', '-ind1', '-ind2', ...,
}

The long version can be useful for further specific analysis.
}
\examples{
\dontrun{
if(interactive()){
  mock_data_core_variants <- unnest(mock_data_core, varianti, keep_empty = TRUE)
  out_companies <- ind_all(data = mock_data_core,
                           data_ind8 = mock_data_core_variants,
                           emergency_name = "coronavirus",
                           target_unit = "companies")
  out_sens <- composite_sensitivity(indicator_list = out_companies,
                                    cutoff = c(0.90, 0.95, 0.99),
                                    TOL = 0.1)  # argument for mirt::mirt function
  View(out_sens$sens_wide)
  View(out_sens$sens_long)

  # regression and ANOVA on sensitivity output
  datl <- out_sens1$sens_long
  datl$ci100 <- 100 * datl$ci
  datl$ind_removed2 <- factor(datl$ind_removed) \%>\% relevel(ref = "none")
  X <- model.matrix(ci100 ~ factor(cutoff) + factor(miss) + factor(weights) + ind_removed2, data = datl)
  y <- datl$ci100
  dat <- data.frame(y, X)
  formula <- paste(names(dat)[-1], collapse = "+")
  formula <- paste("y~", formula)
  mod <- lm(formula, data=dat)
  summary(mod)
  mod_anova <- anova(mod)
  mod_anova

  # graphical visualisation of the results
  # median/mean of CI for each target unit ID
  datw$medianCI <- apply(datw[, -1], MARGIN = 1, FUN = median)
  datw$meanCI <- apply(datw[, -1], MARGIN = 1, FUN = mean)
  datw <- datw \%>\%
    relocate(medianCI, .after = aggregation_name) \%>\%
    relocate(meanCI, .after = medianCI)
  datw_no0 <- datw \%>\%
    filter(meanCI != 0)
  # long data about the first 400 units
  datl_no0 <- datl \%>\%
    filter(aggregation_name \%in\% datw_no0$aggregation_name[1:400]) \%>\%
    left_join(datw_no0 \%>\% select(aggregation_name, medianCI, meanCI)) \%>\%
    arrange(meanCI, aggregation_name)
  aggr <- datl_no0$aggregation_name \%>\% unique
  aggr <- data.frame(id = 1:length(aggr), aggregation_name = aggr)
  datl_no0 <- datl_no0 \%>\% left_join(aggr)
  boxplot(datl_no0$ci ~ datl_no0$id)
 }
}
}
